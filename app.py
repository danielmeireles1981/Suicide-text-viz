import streamlit as st
import pandas as pd
import plotly.express as px
from pathlib import Path
import json

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    page_title="An√°lise de Textos sobre Idea√ß√£o Suicida",
    page_icon="üìä",
    layout="wide"
)

# --- Caminhos (ajuste conforme a estrutura do seu projeto) ---
PROC_PATH = Path("data/processed")
FIGS_PATH = Path("reports/figures")

# --- Fun√ß√µes de Cache para Carregar Dados (melhora a performance) ---
@st.cache_data
def load_data(file_path):
    """Carrega um arquivo CSV de forma segura."""
    if file_path.exists():
        return pd.read_csv(file_path)
    return None

@st.cache_data
def load_json(file_path):
    """Carrega um arquivo JSON de forma segura."""
    if file_path.exists():
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return None

# --- T√≠tulo e Introdu√ß√£o ---
st.title("üìä An√°lise e Visualiza√ß√£o de Textos sobre Idea√ß√£o Suicida")
st.markdown("""
Esta aplica√ß√£o apresenta os resultados da an√°lise de m√∫ltiplos datasets p√∫blicos contendo textos
relacionados √† idea√ß√£o suicida. Explore os gr√°ficos abaixo para entender a estrutura dos dados.
""")

# --- Carregar os dados ---
df_features = load_data(PROC_PATH / "unified_with_features.csv")
df_umap = load_data(PROC_PATH / "umap2_full.csv")
topics = load_json(PROC_PATH / "topics.json")

if df_features is None or df_umap is None:
    st.error(
        "Arquivos de dados n√£o encontrados! "
        "Por favor, execute o pipeline de dados primeiro (`scripts/01_...` a `scripts/06_...`)."
    )
    st.stop()


# --- Layout com Colunas ---
col1, col2 = st.columns(2)

with col1:
    st.header("Balanceamento de Classes")
    balance_img_path = FIGS_PATH / "balanceamento_classes.png"
    if balance_img_path.exists():
        st.image(str(balance_img_path), use_container_width=True)
    else:
        st.warning("Imagem do balanceamento n√£o encontrada.")
    st.info(
        """
        **O que isso significa?**
        Imagine que voc√™ quer ensinar uma m√°quina a diferenciar ma√ß√£s de laranjas, mas voc√™ mostra 100 fotos de ma√ß√£s e apenas 10 de laranjas. A m√°quina pode ficar "viciada" em dizer "ma√ß√£". Da mesma forma, nosso conjunto de dados tem muito mais textos sobre idea√ß√£o suicida (label 1). Isso √© um **ponto de aten√ß√£o**, pois um modelo de IA pode tender a classificar tudo como "idea√ß√£o" por ter visto mais exemplos.
        """
    )

with col2:
    st.header("Correla√ß√£o de Features")
    corr_img_path = FIGS_PATH / "correlacao.png"
    if corr_img_path.exists():
        st.image(str(corr_img_path), use_container_width=True)
    else:
        st.warning("Imagem da correla√ß√£o n√£o encontrada.")
    st.info(
        """
        **O que isso significa?**
        Este "mapa de calor" mostra se caracter√≠sticas simples, como o tamanho do texto ou o n√∫mero de "!", t√™m rela√ß√£o com o fato de ele ser sobre idea√ß√£o suicida. As cores claras, pr√≥ximas de zero, indicam uma **correla√ß√£o muito fraca**. Ou seja, saber que um texto √© longo ou curto n√£o nos ajuda a classific√°-lo. A verdadeira pista est√° no **significado das palavras**, e n√£o nessas contagens superficiais.
        """
    )

st.divider()

# --- Gr√°fico UMAP Interativo ---
st.header("Proje√ß√£o UMAP Interativa")
st.markdown("Passe o mouse sobre os pontos para ver detalhes. Use a legenda para filtrar.")
st.info(
    """
    **Conclus√£o Final: A Hist√≥ria Contada pelo UMAP**

    Este mapa √© a principal ferramenta para entendermos a estrutura do nosso universo de textos. Ele revela duas verdades cruciais:

    1.  **O Problema √© Complexo:** Ao colorir por `label`, vemos que os textos de "idea√ß√£o" e "controle" formam "continentes" distintos, mas suas fronteiras s√£o muito misturadas. Isso prova que a linguagem usada em ambos os casos √©, muitas vezes, parecida, tornando a tarefa de separa√ß√£o um desafio que vai al√©m de simples palavras-chave.

    2.  **Cada Dataset tem um "Sotaque":** Ao colorir por `source`, notamos que os textos se agrupam fortemente de acordo com sua origem (Dataset A, B, C, D). Isso √© um achado cr√≠tico: cada dataset tem um "dialeto" ou estilo de escrita pr√≥prio, provavelmente devido √† plataforma de onde foi extra√≠do (Reddit, Twitter, etc.) ou ao m√©todo de coleta.

    **A Grande Conclus√£o:** A combina√ß√£o desses dois pontos nos leva √† principal conclus√£o do projeto: o maior desafio n√£o √© apenas diferenciar "idea√ß√£o" de "controle", mas faz√™-lo **sem que o modelo de IA "trapaceie" aprendendo o "sotaque" de cada fonte**. Por exemplo, se um dataset √© majoritariamente de "controle" e tem um estilo √∫nico, um modelo pregui√ßoso pode aprender a regra perigosa: *"Se o texto tem esse sotaque, ent√£o n√£o √© idea√ß√£o"*. Este **"vi√©s de fonte" (source bias)** √© a principal armadilha a ser evitada, e o UMAP a torna vis√≠vel e ineg√°vel.
    """
)

color_option = st.selectbox(
    "Colorir proje√ß√£o por:",
    ("label", "source")
)

fig_umap = px.scatter(
    df_umap,
    x="umap1",
    y="umap2",
    color=color_option,
    hover_data={"umap1": False, "umap2": False, color_option: True},
    title=f"Proje√ß√£o UMAP 2D colorida por {color_option}",
    labels={'color': color_option}
)
fig_umap.update_traces(marker=dict(size=5, opacity=0.7))
fig_umap.update_layout(height=700)  # Aumenta a altura do gr√°fico
st.plotly_chart(fig_umap, use_container_width=True)


# --- Amostra dos Dados ---
st.header("Amostra dos Dados Processados")
st.markdown("Abaixo uma amostra aleat√≥ria dos dados unificados e com features.")
st.caption("A coluna `text_clean` cont√©m o texto ap√≥s a limpeza b√°sica, usada para a vetoriza√ß√£o.")
st.dataframe(df_features.sample(10, random_state=42))

st.divider()

# --- An√°lise de Sentimento ---
st.header("An√°lise de Sentimento")
st.markdown(
    "Esta se√ß√£o apresenta a distribui√ß√£o do sentimento (positivo, neutro, negativo) dos textos, "
    "calculado usando a biblioteca `TextBlob`. Isso nos ajuda a entender o tom geral das mensagens."
)

if 'sentiment_label' in df_features.columns:
    sentiment_counts = df_features['sentiment_label'].value_counts().reset_index()
    sentiment_counts.columns = ['Sentimento', 'Contagem']

    # Definir uma ordem para as categorias e cores
    sentiment_order = ['Negativo', 'Neutro', 'Positivo']
    sentiment_colors = {'Negativo': 'red', 'Neutro': 'gray', 'Positivo': 'green'}

    fig_sentiment = px.bar(
        sentiment_counts,
        x='Sentimento',
        y='Contagem',
        title='Distribui√ß√£o de Sentimento dos Textos',
        color='Sentimento',
        color_discrete_map=sentiment_colors,
        category_orders={'Sentimento': sentiment_order}
    )
    st.plotly_chart(fig_sentiment, use_container_width=True)
    st.info(
        """
        **O que isso significa?**
        Como esperado, a grande maioria dos textos tem um tom **negativo**. O interessante √© a presen√ßa de textos classificados como **neutros** ou at√© **positivos**. Isso pode indicar mensagens de apoio, postagens com humor negro, ou express√µes de resigna√ß√£o que n√£o carregam um tom explicitamente negativo, mostrando a diversidade de formas como o tema √© abordado.
        """
    )

    # --- Cruzamento de Sentimento com Classe ---
    st.subheader("An√°lise de Sentimento por Classe")
    sentiment_class_counts = df_features.groupby(['sentiment_label', 'label']).size().reset_index(name='Contagem')
    sentiment_class_counts['Classe'] = sentiment_class_counts['label'].map({0: 'Controle', 1: 'Idea√ß√£o Suicida'})

    fig_cross_sentiment = px.bar(
        sentiment_class_counts,
        x='sentiment_label',
        y='Contagem',
        color='Classe',
        barmode='group',
        title='Distribui√ß√£o de Sentimento Agrupada por Classe',
        labels={'sentiment_label': 'Sentimento do Texto', 'Contagem': 'N√∫mero de Textos'},
        category_orders={'sentiment_label': sentiment_order},
        color_discrete_map={'Controle': '#8888ff', 'Idea√ß√£o Suicida': '#ff6666'}
    )
    st.plotly_chart(fig_cross_sentiment, use_container_width=True)
    st.info(
        """
        **O que isso significa?**
        Este gr√°fico confirma que textos sobre idea√ß√£o suicida s√£o, em sua maioria, negativos. Por√©m, ele revela algo crucial: uma parte significativa desses textos √© classificada como **neutra ou positiva**. Isso mostra que a idea√ß√£o suicida nem sempre √© expressa com palavras de tristeza ou raiva. √Äs vezes, ela pode vir em forma de planejamento calmo ou at√© em textos que parecem otimistas superficialmente, o que torna a detec√ß√£o autom√°tica um desafio ainda maior.
        """
    )

else:
    st.warning("Dados de sentimento n√£o encontrados. Execute o script `06_sentiment_analysis.py`.")

st.divider()

# --- An√°lise de T√≥picos (LDA) ---
st.header("An√°lise de T√≥picos (LDA)")
st.markdown(
    "A Modelagem de T√≥picos √© uma t√©cnica de IA que encontra grupos de palavras semanticamente relacionadas (t√≥picos) "
    "que ocorrem frequentemente juntas nos textos. √â como descobrir as 'receitas' de assuntos que comp√µem nosso conjunto de dados."
)

if topics:
    for topic_name, words in topics.items():
        with st.expander(f"**{topic_name}**"):
            # Formatando as palavras em badges coloridos para melhor visualiza√ß√£o
            word_html = "".join([
                f'<span style="background-color: #e0e0e0; border-radius: 5px; padding: 3px 8px; margin: 3px; display: inline-block;">{word}</span>'
                for word in words
            ])
            st.markdown(word_html, unsafe_allow_html=True)
    st.info(
        """
        **O que esses t√≥picos significam?**
        Cada "t√≥pico" √© um conjunto de palavras que a IA descobriu que aparecem frequentemente juntas. Eles representam os principais temas discutidos nos textos. Por exemplo, um t√≥pico com palavras como `[vida, morrer, quero, dor, fim]` est√° claramente relacionado a express√µes diretas de idea√ß√£o suicida. Outro t√≥pico com `[escola, trabalho, amigos, fam√≠lia]` pode representar os estressores da vida cotidiana que s√£o mencionados nos textos. Analisar esses temas nos ajuda a entender o contexto em que a idea√ß√£o suicida √© discutida.
        """
    )
else:
    st.warning("Arquivo de t√≥picos (`topics.json`) n√£o encontrado. Execute o script `05_topic_modeling.py`.")

st.divider()

# --- Conclus√£o Geral e Pr√≥ximos Passos ---
st.header("Conclus√£o Geral do Projeto e Pr√≥ximos Passos")
st.markdown(
    """
    A pergunta que surge da an√°lise UMAP √©: *"Se os datasets s√£o t√£o diferentes, a an√°lise √© inv√°lida?"*

    **A resposta √© o oposto.** A principal conclus√£o deste projeto **n√£o √© um fracasso**, mas sim um **sucesso anal√≠tico crucial**: a descoberta e visualiza√ß√£o do **"vi√©s de fonte" (source bias)**.

    - **O que descobrimos:** Descobrimos que os datasets n√£o formam um grupo homog√™neo. Eles t√™m "sotaques" distintos. A rela√ß√£o entre eles √© de maior ou menor semelhan√ßa estil√≠stica, e n√£o de uniformidade.

    - **Por que isso √© valioso:** Essa descoberta nos protege de criar um modelo de IA ing√™nuo e perigoso. Um modelo treinado em todos esses dados juntos aprenderia a "trapacear", usando o "sotaque" de cada fonte para adivinhar a classe, em vez de entender o conte√∫do real sobre idea√ß√£o suicida. Ele teria um bom desempenho em dados de teste *do mesmo conjunto*, mas falharia catastroficamente no mundo real.

    **Pr√≥ximos Passos Sugeridos:**
    1.  **Modelagem Consciente do Vi√©s:** Em vez de um √∫nico modelo, poder√≠amos treinar modelos separados para cada "dialeto" ou usar t√©cnicas avan√ßadas de *Domain Adaptation* para ensinar um modelo a ignorar o "sotaque".
    2.  **Valida√ß√£o Robusta:** Criar um conjunto de valida√ß√£o com dados de uma fonte completamente nova seria a √∫nica maneira de medir verdadeiramente a capacidade de generaliza√ß√£o de um modelo.
    """
)
