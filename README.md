# AnÃ¡lise e VisualizaÃ§Ã£o de Textos sobre IdeaÃ§Ã£o Suicida

Este projeto realiza a unificaÃ§Ã£o, limpeza, engenharia de features e visualizaÃ§Ã£o de dois datasets pÃºblicos contendo textos relacionados Ã  ideaÃ§Ã£o suicida. O objetivo Ã© explorar as caracterÃ­sticas dos textos e visualizar a separaÃ§Ã£o entre as classes (ideaÃ§Ã£o vs. controle) usando tÃ©cnicas de reduÃ§Ã£o de dimensionalidade como UMAP e t-SNE.

## Resultados Visuais

Abaixo estÃ£o alguns dos grÃ¡ficos gerados pelo pipeline de anÃ¡lise:

| Balanceamento de Classes | CorrelaÃ§Ã£o de Features |
| :---: | :---: |
| ![Balanceamento de Classes](reports/figures/balanceamento_classes.png) | ![CorrelaÃ§Ã£o de Features](reports/figures/correlacao.png) |

| ProjeÃ§Ã£o UMAP por RÃ³tulo | ProjeÃ§Ã£o UMAP por Fonte do Dataset |
| :---: | :---: |
| ![UMAP por RÃ³tulo](reports/figures/umap_label.png) | ![UMAP por Fonte](reports/figures/umap_source.png) |

## Estrutura do Projeto

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # â¬…ï¸ Os datasets do Kaggle devem ser colocados aqui
â”‚   â””â”€â”€ processed/    # â¡ï¸ Arquivos gerados pelo pipeline
â”œâ”€â”€ notebooks/        # Notebooks para exploraÃ§Ã£o e prototipagem
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/      # â¡ï¸ GrÃ¡ficos e figuras gerados
â”œâ”€â”€ scripts/          # Scripts para executar o pipeline de dados
â”‚   â”œâ”€â”€ 01_unify_datasets.py
â”‚   â”œâ”€â”€ 02_build_features.py
â”‚   â”œâ”€â”€ 03_vectorize_project.py
â”‚   â””â”€â”€ 04_make_plots.py
â”œâ”€â”€ src/              # CÃ³digo fonte reutilizÃ¡vel (funÃ§Ãµes)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸš€ Setup e InstalaÃ§Ã£o

Siga os passos abaixo para configurar e executar o projeto localmente.

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/danielmeireles1981/Suicide-text-viz.git
cd Suicide-text-viz
```

### 2. Baixe os Datasets

Este projeto nÃ£o inclui os dados no repositÃ³rio. VocÃª precisa baixÃ¡-los manualmente do Kaggle e colocÃ¡-los na pasta `data/raw/`.

1.  **Crie a pasta:**
    ```bash
    mkdir -p data/raw
    ```

2.  **Baixe os seguintes arquivos e salve-os em `data/raw/`:**
    *   **Dataset A:** Suicide and Depression Detection
        *   Nome do arquivo esperado: `Suicide_Detection.csv`
    *   **Dataset B:** Suicide Ideation Detection Dataset
        *   Nome do arquivo esperado: `Suicide_Ideation_Dataset(Twitter-based).csv`

### 3. Crie o Ambiente Virtual e Instale as DependÃªncias

Ã‰ altamente recomendado usar um ambiente virtual para isolar as dependÃªncias do projeto.

```bash
# Crie um ambiente virtual (ex: .venv)
python -m venv .venv

# Ative o ambiente
# No Windows (PowerShell):
.\.venv\Scripts\Activate.ps1
# No macOS/Linux:
# source .venv/bin/activate

# Instale as bibliotecas necessÃ¡rias
pip install -r requirements.txt
```

## âš™ï¸ Como Executar o Pipeline

Com o ambiente ativado e os dados no lugar certo, execute os scripts na ordem correta para processar os dados e gerar os resultados.

```bash
# 1. Unifica e limpa os datasets
python scripts/01_unify_datasets.py

# 2. Cria features numÃ©ricas a partir do texto
python scripts/02_build_features.py

# 3. Vetoriza os textos e cria as projeÃ§Ãµes (PCA, UMAP, t-SNE)
python scripts/03_vectorize_project.py

# 4. Gera todos os grÃ¡ficos e os salva em reports/figures/
python scripts/04_make_plots.py
```

Ao final da execuÃ§Ã£o, a pasta `reports/figures/` conterÃ¡ todos os grÃ¡ficos atualizados.